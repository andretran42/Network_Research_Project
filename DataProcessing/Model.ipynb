{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import ipaddress\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import train_test_split as tts      \n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "from sklearn.metrics import confusion_matrix as CM \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score as AS\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn import tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fortnite1_continuousupdown.csv', 'Wikipedia2_singledown.csv', 'hulu3_continuous-download.csv', 'Wikipedia5_singledown.csv', 'chatgpt3_singleupdown.csv', 'ryrod2_singledown.csv', 'ryrod3_singledown.csv', 'amazon1_singleupdown.csv', 'bing3_singleupdown.csv', 'Wikipedia4_singledown.csv', 'Wikipedia3_singledown.csv', 'discord3_continuousupdown.csv', 'Wikipedia1_singledown.csv', 'amazon4_singleupdown.csv', 'ryrod1_singledown.csv', 'chatgpt2_singleupdown.csv', 'bing_singleupdown.csv', 'chatgpt_singleupdown.csv', 'bing2_singleupdown.csv', 'discord2_continuousupdown.csv', 'minecraft1_continuousupdown.csv', 'minecraft4_continuousupdown.csv', 'ugm5_singledown.csv', 'minecraft2_continuousupdown.csv', 'bing5_singleupdown.csv', 'discord1_continuousupdown.csv', 'discord4_continuousupdown.csv', 'ugm2_singledown.csv', 'ugm3_singledown.csv', 'fortnite3_continuousupdown.csv', 'hulu2_continuous-download.csv', 'ugm4_singledown.csv', 'amazon3_singleupdown.csv', 'bing4_singleupdown.csv', 'hulu1_continuous-download.csv', 'ugm1_singledown.csv', 'minecraft3_continuousupdown.csv', 'chatgpt4_singleupdown.csv', 'amazon2_singleupdown.csv', 'fortnite2_continuousupdown.csv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Length</th>\n",
       "      <th>Website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010276</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048486</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050166</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076227</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28173</th>\n",
       "      <td>6.244447</td>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28174</th>\n",
       "      <td>6.250256</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28175</th>\n",
       "      <td>6.280475</td>\n",
       "      <td>3</td>\n",
       "      <td>201</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28176</th>\n",
       "      <td>6.315326</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28177</th>\n",
       "      <td>6.346554</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27971 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time Protocol  Length  Website\n",
       "0      0.000000        3      97        5\n",
       "1      0.010276        3      82        5\n",
       "2      0.048486        3      83        5\n",
       "3      0.050166        3     120        5\n",
       "4      0.076227        3      82        5\n",
       "...         ...      ...     ...      ...\n",
       "28173  6.244447        3     108        5\n",
       "28174  6.250256        3      82        5\n",
       "28175  6.280475        3     201        5\n",
       "28176  6.315326        3      83        5\n",
       "28177  6.346554        3      82        5\n",
       "\n",
       "[27971 rows x 4 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATA PROCESSING#\n",
    "\n",
    "#Include all .csv files in directory of this code #\n",
    "\n",
    "all_files = glob.glob(\"*.csv\")\n",
    "print(all_files)\n",
    "li = []\n",
    "#print(path)\n",
    "data = pd.concat((pd.read_csv(f,index_col='No.') for f in all_files),ignore_index=True)\n",
    "\n",
    "#Init Website Target#\n",
    "data['Website'] = 100\n",
    "\n",
    "#Website Target Labels and IP Addresses#\n",
    "#SINGLE UP DOWN #\n",
    "\n",
    "# (1-4) Amazon = 1\n",
    "amaz_src_dest = [\"18.160.17.214\",\"18.165.77.79\"] #TCP\n",
    "data.loc[data['Source'] == amaz_src_dest[0],'Website'] = 1\n",
    "data.loc[data['Source'] == amaz_src_dest[1],'Website'] = 1\n",
    "data.loc[data['Destination'] == amaz_src_dest[0],'Website'] = 1\n",
    "data.loc[data['Destination'] == amaz_src_dest[1],'Website'] = 1\n",
    "\n",
    "# (1-5) Bing = 2\n",
    "bing_src_dest = [\"204.79.197.200\"] #TCP\n",
    "data.loc[data['Source'] == bing_src_dest[0],'Website'] = 2\n",
    "data.loc[data['Destination'] == bing_src_dest[0],'Website'] = 2\n",
    "\n",
    "# (1-4) ChatGPT = 3 \n",
    "chat_src_dest = [\"104.18.37.228\"] # TCP\n",
    "data.loc[data['Source'] == chat_src_dest[0],'Website'] = 3\n",
    "data.loc[data['Destination'] == chat_src_dest[0],'Website'] = 3\n",
    "\n",
    "#CONTINUOUS UP DOWN #\n",
    "# (1-4) Discord CHAT CONTINUOUS = 4\n",
    "discCHAT_src_dest = [\"66.22.231.191\"] # UDP\n",
    "data.loc[data['Source'] == discCHAT_src_dest[0],'Website'] = 4\n",
    "data.loc[data['Destination'] == discCHAT_src_dest[0],'Website'] = 4\n",
    "\n",
    "# (1-3) Fortnite = 5\n",
    "fort_src_dest = [\"20.36.181.22\",\"3.129.219.222\",\"3.144.65.185\"] # UDP\n",
    "data.loc[data['Source'] == fort_src_dest[0],'Website'] = 5\n",
    "data.loc[data['Source'] == fort_src_dest[1],'Website'] = 5\n",
    "data.loc[data['Source'] == fort_src_dest[2],'Website'] = 5\n",
    "data.loc[data['Destination'] == fort_src_dest[0],'Website'] = 5\n",
    "data.loc[data['Destination'] == fort_src_dest[1],'Website'] = 5\n",
    "data.loc[data['Destination'] == fort_src_dest[2],'Website'] = 5\n",
    "\n",
    "# (1-4) Minecraft = 6 #TCP\n",
    "mine_src_dest = [\"209.222.115.47\",\"104.234.169.167\",\"31.25.11.18\",\"31.25.11.55\"]\n",
    "data.loc[data['Source'] == mine_src_dest[0],'Website'] = 6\n",
    "data.loc[data['Source'] == mine_src_dest[1],'Website'] = 6\n",
    "data.loc[data['Source'] == mine_src_dest[2],'Website'] = 6\n",
    "data.loc[data['Source'] == mine_src_dest[3],'Website'] = 6\n",
    "data.loc[data['Destination'] == mine_src_dest[0],'Website'] = 6\n",
    "data.loc[data['Destination'] == mine_src_dest[1],'Website'] = 6\n",
    "data.loc[data['Destination'] == mine_src_dest[2],'Website'] = 6\n",
    "data.loc[data['Destination'] == mine_src_dest[3],'Website'] = 6\n",
    "\n",
    "#SINGLE DOWN #\n",
    "# (1-5) Wikipedia = 0\n",
    "wiki_src_dest = [\"208.80.154.224\"] #TCP\n",
    "data.loc[data['Source'] == wiki_src_dest[0],'Website'] = 0 \n",
    "data.loc[data['Destination'] == wiki_src_dest[0],'Website'] = 0 \n",
    "\n",
    "#ryrob (1-3) = 7\n",
    "ryrob_src_dest = [\"172.66.40.147\"] #QUIC\n",
    "data.loc[data['Source'] == ryrob_src_dest[0],'Website'] = 7\n",
    "data.loc[data['Destination'] == ryrob_src_dest[0],'Website'] = 7\n",
    "\n",
    "#ugm.org (1-5) = 8\n",
    "ugm_src_dest = [\"13.84.36.2\"] #TCP TLSv1.2\n",
    "data.loc[data['Source'] == ugm_src_dest[0],'Website'] = 8\n",
    "data.loc[data['Destination'] == ugm_src_dest[0],'Website'] = 8\n",
    "\n",
    "#CONTINUOUS DOWN #\n",
    "#(1-3) HULU = 9\n",
    "hulu_src_dest = [\"23.48.104.108\", \"23.48.104.112\",\"23.48.104.110\"] #TCP TLSv1.2\n",
    "data.loc[data['Source'] == hulu_src_dest[0],'Website'] = 9\n",
    "data.loc[data['Source'] == hulu_src_dest[1],'Website'] = 9\n",
    "data.loc[data['Source'] == hulu_src_dest[2],'Website'] = 9\n",
    "data.loc[data['Destination'] == hulu_src_dest[0],'Website'] = 9\n",
    "data.loc[data['Destination'] == hulu_src_dest[1],'Website'] = 9\n",
    "data.loc[data['Destination'] == hulu_src_dest[2],'Website'] = 9\n",
    "\n",
    "#\n",
    "data.drop(columns = ['Info'], inplace = True)\n",
    "#Drop random IP addresses and Protocol\n",
    "data = data.drop(data[data['Website'] == 100].index)\n",
    "# data = data.drop(data[data['Protocol'] == \"RTCP\"].index)\n",
    "#Convert IP addresses to Integers\n",
    "data['Source'] = data['Source'].apply(lambda x : int(ipaddress.ip_address(x)))\n",
    "data['Destination'] = data['Destination'].apply(lambda x : int(ipaddress.ip_address(x)))\n",
    "\n",
    "#Convert Protocols to ints\n",
    "#QUIC = 1\n",
    "#TCP/TLS = 2\n",
    "#UDP = 3 \n",
    "#RTCP = 4\n",
    "data.loc[data['Protocol'] == \"QUIC\",'Protocol'] = 1\n",
    "data.loc[data['Protocol'] == \"TLSv1.2\",'Protocol'] = 2\n",
    "data.loc[data['Protocol'] == \"TLSv1.3\",'Protocol'] = 2\n",
    "data.loc[data['Protocol'] == \"TCP\",'Protocol'] = 2\n",
    "data.loc[data['Protocol'] == \"UDP\",'Protocol'] = 3\n",
    "data.loc[data['Protocol'] == \"RTCP\",'Protocol'] = 4\n",
    "\n",
    "\n",
    "data.drop(columns = ['Source','Destination'], inplace = True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        5\n",
       "1        5\n",
       "2        5\n",
       "3        5\n",
       "4        5\n",
       "        ..\n",
       "28173    5\n",
       "28174    5\n",
       "28175    5\n",
       "28176    5\n",
       "28177    5\n",
       "Name: Website, Length: 27971, dtype: int64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:,0:3]\n",
    "y = data.iloc[:,3]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X,y,random_state=17, test_size = 0.33)\n",
    " \n",
    "# scaler = SS()  \n",
    "#  # Don't cheat - fit only on training data\n",
    "# scaler.fit(X_train) \n",
    "\n",
    "# X_train = scaler.transform(X_train)  \n",
    "#  # apply same transformation to test data\n",
    "# X_test = scaler.transform(X_test)  \n",
    "#X_test.reshape(-1,5)\n",
    "\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. KNeighborsClassifier expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[219], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNN(n_neighbors \u001b[38;5;241m=\u001b[39m i)\n\u001b[1;32m      5\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m----> 6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m acc \u001b[38;5;241m=\u001b[39m AS(y_pred,y_test)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;132;01m{i}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m,acc)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:261\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/sklearn/neighbors/_base.py:804\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    802\u001b[0m         X \u001b[38;5;241m=\u001b[39m _check_precomputed(X)\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 804\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/sklearn/utils/validation.py:953\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    950\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    951\u001b[0m     )\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m     )\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m    959\u001b[0m     _assert_all_finite(\n\u001b[1;32m    960\u001b[0m         array,\n\u001b[1;32m    961\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    962\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    963\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    964\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. KNeighborsClassifier expected <= 2."
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "for i in range(2,10):\n",
    "    knn = KNN(n_neighbors = i)\n",
    "\n",
    "    knn.fit(X_train,y_train)\n",
    "    y_pred = knn.predict(x_test)\n",
    "    acc = AS(y_pred,y_test)\n",
    "    print(\"accuracy{i}:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 148,   18,   27,   10,    0,    0,   33,    0,   26,   12],\n",
       "       [   5,  397,   15,   19,    0,    0,   16,    0,   10,   19],\n",
       "       [  30,   28, 1912,   22,    0,    0,   75,    0,   31,   39],\n",
       "       [  14,   26,   18,  372,    0,    0,   12,    0,    6,   26],\n",
       "       [   0,    0,    0,    0,  698,   47,    0,    9,    0,    0],\n",
       "       [   0,    0,    0,    0,   42,  647,    0,    9,    0,    0],\n",
       "       [  42,   21,   70,   24,    0,    0,  991,    0,   45,   46],\n",
       "       [   0,    0,    0,    0,   10,    5,    0, 1310,    0,    0],\n",
       "       [  37,    7,   37,    7,    0,    0,   29,    0,  771,    8],\n",
       "       [  11,   24,   25,   18,    0,    0,   23,    0,   10,  842]])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = dtc()\n",
    "tree.fit(X_train,y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "CM(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Wikipedia       0.52      0.54      0.53       274\n",
      "      Amazon       0.76      0.83      0.79       481\n",
      "        Bing       0.91      0.89      0.90      2137\n",
      "        Chat       0.79      0.78      0.79       474\n",
      "     Discord       0.93      0.93      0.93       754\n",
      "    Fortnite       0.93      0.93      0.93       698\n",
      "   Minecraft       0.84      0.80      0.82      1239\n",
      "       ryrob       0.99      0.99      0.99      1325\n",
      "         ugm       0.86      0.86      0.86       896\n",
      "        hulu       0.85      0.88      0.87       953\n",
      "\n",
      "    accuracy                           0.88      9231\n",
      "   macro avg       0.84      0.84      0.84      9231\n",
      "weighted avg       0.88      0.88      0.88      9231\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>0.481492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Protocol</th>\n",
       "      <td>0.236851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length</th>\n",
       "      <td>0.281657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "Time      0.481492\n",
       "Protocol  0.236851\n",
       "Length    0.281657"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#['Wikipedia','Amazon','Bing','Chat','Discord','Fortnite','Minecraft','ryrob','ugm','hulu']\n",
    "print(classification_report(y_test,y_pred,target_names= ['Wikipedia','Amazon','Bing','Chat','Discord','Fortnite','Minecraft','ryrob','ugm','hulu']))\n",
    "features = pd.DataFrame(tree.feature_importances_,index = X.columns)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(18740, 1), dtype=int64, numpy=\n",
       "array([[1],\n",
       "       [4],\n",
       "       [1],\n",
       "       ...,\n",
       "       [2],\n",
       "       [8],\n",
       "       [0]])>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TensorFlow Setup\n",
    "\n",
    "features = data.drop(columns='Website').to_numpy()\n",
    "labels = data['Website'].to_numpy()\n",
    "features = np.expand_dims(features,-1)\n",
    "labels = np.expand_dims(labels,-1)\n",
    "#x_tensor = tf.convert_to_tensor(features, dtype=tf.int64) \n",
    "#y_tensor = tf.convert_to_tensor(labels, dtype=tf.int64) \n",
    "x_train, x_test,y_train,y_test = tts(features,labels,test_size=0.33,shuffle=True)\n",
    "x_tensor = tf.convert_to_tensor(x_train, dtype=tf.int64) \n",
    "y_tensor = tf.convert_to_tensor(y_train, dtype=tf.int64) \n",
    "x_tensor\n",
    "y_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/mean_squared_error/BroadcastGradientArgs' defined at (most recent call last):\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/th/t0lfd8fx2dd8yyzcv6_91y7c0000gn/T/ipykernel_16196/4270130018.py\", line 31, in <module>\n      history= model.fit(x_tensor,y_tensor,batch_size = 100,epochs = 400)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizers/optimizer_v1.py\", line 872, in minimize\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/mean_squared_error/BroadcastGradientArgs'\nIncompatible shapes: [100,5,10] vs. [100,1]\n\t [[{{node gradient_tape/mean_squared_error/BroadcastGradientArgs}}]] [Op:__inference_train_function_329426]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[200], line 31\u001b[0m\n\u001b[1;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mAdamOptimizer(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m),\n\u001b[1;32m     27\u001b[0m             loss \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     28\u001b[0m             metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# model.compile(optimizer = 'adam', loss = \"mse\",metrics=['accuracy'])\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#model.summary()\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m history\u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/mean_squared_error/BroadcastGradientArgs' defined at (most recent call last):\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/th/t0lfd8fx2dd8yyzcv6_91y7c0000gn/T/ipykernel_16196/4270130018.py\", line 31, in <module>\n      history= model.fit(x_tensor,y_tensor,batch_size = 100,epochs = 400)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/engine/training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/Users/coltonturner/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizers/optimizer_v1.py\", line 872, in minimize\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/mean_squared_error/BroadcastGradientArgs'\nIncompatible shapes: [100,5,10] vs. [100,1]\n\t [[{{node gradient_tape/mean_squared_error/BroadcastGradientArgs}}]] [Op:__inference_train_function_329426]"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    #keras.layers.Dense(len(x_tensor)),\n",
    "    keras.layers.Dense(f),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10,activation=tf.nn.softmax)\n",
    "])\n",
    "# model.add(tf.keras.layers.Dense(1024))\n",
    "# model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.Dense(units=6, activation='relu', input_shape=[6,]))\n",
    "# model.add(tf.keras.layers.Dense(units=20, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(units=25, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(units=20, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(units=1, activation='relu'))\n",
    "    # keras.layers.Dense(x_tensor,kernel_regularizer=tf.keras.regularizers(0.1)),\n",
    "    # keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer=tf.kerars.regularizers(0.1)),\n",
    "    # keras.layers.Dense(256, activation=tf.nn.relu, kernel_regularizer=tf.kerars.regularizers(0.1)),\n",
    "    # keras.layers.Dense(128, activation=tf.nn.relu, kernel_regularizer=tf.kerars.regularizers(0.1)),\n",
    "    # keras.layers.Dense(10,activation=tf.nn.softmax)\n",
    "\n",
    "model.compile(optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=0.001),\n",
    "            loss ='mse',\n",
    "            metrics=['accuracy'])\n",
    "# model.compile(optimizer = 'adam', loss = \"mse\",metrics=['accuracy'])\n",
    "#model.summary()\n",
    "history= model.fit(x_tensor,y_tensor,batch_size = 100,epochs = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 3, 1)]            0         \n",
      "                                                                 \n",
      " simple_rnn_4 (SimpleRNN)    (None, 32)                1088      \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,121\n",
      "Trainable params: 1,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/4\n",
      "9370/9370 [==============================] - 13s 1ms/step - loss: 7.2564 - accuracy: 0.0535\n",
      "Epoch 2/4\n",
      "9370/9370 [==============================] - 13s 1ms/step - loss: 7.1583 - accuracy: 0.0535\n",
      "Epoch 3/4\n",
      "9370/9370 [==============================] - 12s 1ms/step - loss: 7.0488 - accuracy: 0.0535\n",
      "Epoch 4/4\n",
      "9370/9370 [==============================] - 12s 1ms/step - loss: 7.1564 - accuracy: 0.0535\n"
     ]
    }
   ],
   "source": [
    "#Model Fitting\n",
    "inputs = tf.keras.layers.Input(shape=(x_tensor.shape[1],x_tensor.shape[2]))\n",
    "rnn_out = tf.keras.layers.SimpleRNN(32)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(rnn_out)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs,outputs=[outputs])\n",
    "model.compile(optimizer = 'adam', loss = \"cross\",metrics=['accuracy'])\n",
    "model.summary()\n",
    "history= model.fit(x_tensor,y_tensor,batch_size = 2,epochs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
